# 测试日志：agent_as_judge（Agent 作为裁判）

> 测试尚未运行。请运行各文件后更新本日志。

### agent_as_judge_basic.py

**状态：** PENDING（待测试）

**说明：** 运行同步与异步 Agent-as-judge（Agent 作为裁判）评估。

---

### agent_as_judge_post_hook.py

**状态：** PENDING（待测试）

**说明：** 运行同步与异步后置钩子质量评估流程。

---

### agent_as_judge_batch.py

**状态：** PENDING（待测试）

**说明：** 在一次批量运行中评估多个客服案例。

---

### agent_as_judge_binary.py

**状态：** PENDING（待测试）

**说明：** 执行二元 PASS/FAIL（通过/失败）语气评估。

---

### agent_as_judge_custom_evaluator.py

**状态：** PENDING（待测试）

**说明：** 使用自定义 Evaluator（评估器）Agent 评估响应。

---

### agent_as_judge_team.py

**状态：** PENDING（待测试）

**说明：** 对研究 Team（团队）的响应质量进行评分。

---

### agent_as_judge_team_post_hook.py

**状态：** PENDING（待测试）

**说明：** 运行后置钩子 Team（团队）评估并打印存储的评分详情。

---

### agent_as_judge_with_guidelines.py

**状态：** PENDING（待测试）

**说明：** 使用明确的附加指导方针评估输出质量。

---

### agent_as_judge_with_tools.py

**状态：** PENDING（待测试）

**说明：** 对工具辅助的数学响应质量进行评分。

---
